{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a04658",
   "metadata": {},
   "source": [
    "## Best Model for Predicting Stroke -  \n",
    "\n",
    "XGBoost for Classification is the best model for predicting Stroke. Below is the final code for this model which would be used hereafter for putting as a web service using Flask and local deployment using Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d32a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all the basic libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddedc0d8",
   "metadata": {},
   "source": [
    "Loading the Dataset - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0443ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the data from csv file into Pandas DataFrame:\n",
    "data = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d277039",
   "metadata": {},
   "source": [
    "Data Cleaning and Formatting -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74492c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Cleaning and Formatting -  \n",
    "# formatting column names and row values to lower case:\n",
    "data.columns = data.columns.str.lower()\n",
    "data['smoking_status'] = data['smoking_status'].str.lower()\n",
    "data['work_type'] = data['work_type'].str.lower()\n",
    "\n",
    "# imputing missing values in BMI column with mean BMI values:\n",
    "data['bmi'] = data['bmi'].fillna(np.mean(data['bmi']))\n",
    "\n",
    "# dropping id column from dataset:\n",
    "data.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# getting the mode of gender column:\n",
    "gender_mode = list(data.gender.mode().values)[0]\n",
    "\n",
    "# replacing the 'Other' gender category row to mode of gender column:\n",
    "data['gender'] = data['gender'].replace('Other', gender_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44a12e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating numerical variable columns and categorical variable columns:\n",
    "numerical = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "# remaining columns are categorical variable columns:\n",
    "categorical = ['gender','hypertension','heart_disease', 'ever_married', 'work_type', \n",
    "                        'residence_type','smoking_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89503f7",
   "metadata": {},
   "source": [
    "Splitting the Data and getting the Feature Matrix & Target variables - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91c2c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3066, 10), (1022, 10), (1022, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Splitting the Data &  getting the Feature Matrix & Target variables - \n",
    "# splitting the dataset using sklearn into 60-20-20:\n",
    "# Step 1 - splitting dataset into full train and test subsets first:\n",
    "df_full_train, df_test = train_test_split(data, test_size=0.2,random_state=1)\n",
    "\n",
    "# Step 2 - splitting full train subset again into training set and validation set:\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25,random_state = 1)\n",
    "\n",
    "# Resetting indices for each of the subset: \n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Getting our target variable column ('stroke') subsets as respective Numpy arrays:\n",
    "y_train = df_train.stroke.values\n",
    "y_val = df_val.stroke.values\n",
    "y_test = df_test.stroke.values\n",
    "\n",
    "# deleting 'stroke' column from feature matrix subsets:\n",
    "del df_train['stroke']\n",
    "del df_val['stroke']\n",
    "del df_test['stroke']\n",
    "\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875977e",
   "metadata": {},
   "source": [
    "Predicting on Test data using our Final Model (XGBoost for Classification) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddea9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predicting on Test data using our Final Model - \n",
    "# resetting indices of full_train DataFrame:\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "\n",
    "# slicing the target variable column for full_train dataset:\n",
    "y_full_train = (df_full_train.stroke).astype(int).values\n",
    "\n",
    "# turning the full train df into dictionaries:\n",
    "dicts_full_train = df_full_train.to_dict(orient='records')\n",
    "\n",
    "# instantiating the vectorizer instance:\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# turning list of dictionaries into full train feature matrix\n",
    "X_full_train = dv.fit_transform(dicts_full_train)\n",
    "\n",
    "# turning the test df into dictionaries:\n",
    "dicts_test = df_test.to_dict(orient='records')\n",
    "\n",
    "# turning list of dictionaries into testing feature matrix\n",
    "X_test = dv.transform(dicts_test)\n",
    "\n",
    "# converting full train and test matrices into DMatrix datastructure for using in XGBoost model:\n",
    "dfulltrain = xgb.DMatrix(X_full_train, label = y_full_train, feature_names = dv.get_feature_names())\n",
    "dtest = xgb.DMatrix(X_test, feature_names = dv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a4645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'eta': 0.1, \n",
    "              'max_depth': 3, \n",
    "              'min_child_weight': 20,\n",
    "             'objective': 'binary:logistic',\n",
    "              'eval_metric':'auc',\n",
    "              \n",
    "             'nthread': 8,\n",
    "             'seed': 1,\n",
    "             'verbosity': 1}\n",
    "\n",
    "\n",
    "# training our best model XGBoost on our full train set:\n",
    "model = xgb.train(xgb_params, dfulltrain, num_boost_round=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d88fce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test set: 0.852\n"
     ]
    }
   ],
   "source": [
    "# predicting the XGBoost model on the testing set:\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# computing the AUC score on testing set:\n",
    "print('AUC on test set: %.3f' % roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d245681",
   "metadata": {},
   "source": [
    "#### Using KFold Cross-Validation on our Final Model for making Predictions - \n",
    "\n",
    "(making 5-fold cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f313025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 -\n",
    "# Function 1 - Creating a function to train our DataFrame:\n",
    "def train(df_train, y_train):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "    \n",
    "    # converting full train and test matrices into DMatrix datastructure for using in XGBoost model:\n",
    "    dtrain = xgb.DMatrix(X_train, label = y_train, feature_names = dv.get_feature_names())\n",
    "    model = xgb.train(xgb_params,dtrain, num_boost_round=200)     \n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504e0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - \n",
    "# Function 2 - Creating another function to predict:\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')  # converts df to list of dictionaries\n",
    "    \n",
    "    X = dv.transform(dicts)  # creates a feature matrix using the vectorizer\n",
    "    \n",
    "    X_Dmat = xgb.DMatrix(X, feature_names = dv.get_feature_names())\n",
    "    y_pred = model.predict(X_Dmat)  # uses the model\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0ea6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the number of folds to be used:\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f365e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833 +- 0.023\n"
     ]
    }
   ],
   "source": [
    "# Performing K-fold Cross validation and evaluating the AUC scores after each iteration:\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "        \n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        \n",
    "    # Selecting part of dataset as 3 subsets for model:\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.stroke.values   # our target variable values as Numpy array for train and validation sets\n",
    "    y_val = df_val.stroke.values\n",
    "\n",
    "    dv, model = train(df_train, y_train)   # using train function created\n",
    "    y_pred = predict(df_val, dv, model)   # using predict function created\n",
    "\n",
    "    # compute auc scores for each iteration or fold in KFold:\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "        \n",
    "# Computing mean of AUC scores and spread of AUC score:\n",
    "print('%.3f +- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d38b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8375210066811494,\n",
       " 0.8320853887714352,\n",
       " 0.8705228916496522,\n",
       " 0.8250456050266874,\n",
       " 0.7988926240854262]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the listing of AUC scores in each fold:\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652e629b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8430873180873182"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, Training our Final Model on Full train dataset and evaluating on test dataset -\n",
    "dv, model = train(df_full_train, df_full_train.stroke.values)   # using train function created\n",
    "y_pred = predict(df_test, dv, model)   # using predict function created\n",
    "\n",
    "# compute auc for ROC Curve:\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d92e84",
   "metadata": {},
   "source": [
    "#### Saving the Model -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cf0d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd5e6fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.bin'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - taking our model and writing it to a file - \n",
    "# creating a file where we'll write it:\n",
    "output_file = f'model.bin'                  \n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df4600e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a Binary file using pickle - alternative to open and close codes we use with open to automatically open-close a file:\n",
    "with open(output_file, 'wb') as f_out:    # file output\n",
    "    pickle.dump((dv, model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f201c887",
   "metadata": {},
   "source": [
    "#### Loading the Model - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a38ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e615ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a variable with our model file:\n",
    "input_file = 'model.bin'\n",
    "\n",
    "# loads our model file: \n",
    "with open(input_file, 'rb') as f_in:    # file input; rb - used to read the file\n",
    "    dv, model = pickle.load(f_in)     # load() function reads from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e4946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x27e98086580>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ed52b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a sample person's stroke-related details (to test and predict our model on unseen person's details) - \n",
    "sample_person = {'age': 75.0,\n",
    " 'avg_glucose_level': 170.01,\n",
    " 'bmi': 35.5,\n",
    " 'gender': 'Male',\n",
    " 'hypertension': 0,\n",
    " 'heart_disease': 1,\n",
    " 'ever_married': 'Yes',\n",
    " 'work_type': 'private',\n",
    " 'residence_type': 'Rural',\n",
    " 'smoking_status': 'smokes'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65ee560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the sample person's feature details into a dictionary using DictVectorizer:\n",
    "X = dv.transform([sample_person])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66a04209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the transformed feature matrix of sample person to DMatrix for use in XGBoost model:\n",
    "X_Dm = xgb.DMatrix(X, feature_names = dv.get_feature_names())\n",
    "\n",
    "# make prediction on sample person using our model: \n",
    "y_pred = model.predict(X_Dm)  # By default, the predictions made by XGBoost are probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be1ca78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: {'age': 75.0, 'avg_glucose_level': 170.01, 'bmi': 35.5, 'gender': 'Male', 'hypertension': 0, 'heart_disease': 1, 'ever_married': 'Yes', 'work_type': 'private', 'residence_type': 'Rural', 'smoking_status': 'smokes'}\n",
      "output: 0.3430485129356384\n"
     ]
    }
   ],
   "source": [
    "print('input:', sample_person)\n",
    "print('output:', float(y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2f4a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stroke decision by specifying the threshold:\n",
    "stroke = float(y_pred) >= 0.55 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bde6b1",
   "metadata": {},
   "source": [
    "Making requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d76ff90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7c42e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_person = {'age': 75.0,\n",
    " 'avg_glucose_level': 170.01,\n",
    " 'bmi': 35.5,\n",
    " 'gender': 'Male',\n",
    " 'hypertension': 0,\n",
    " 'heart_disease': 1,\n",
    " 'ever_married': 'Yes',\n",
    " 'work_type': 'private',\n",
    " 'residence_type': 'Rural',\n",
    " 'smoking_status': 'smokes'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cf11211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the sample person's feature details into json format (dictionaries):\n",
    "#requests.post(url,json =sample_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "411a9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = requests.post(url,json=sample_person).json()\n",
    "#response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5ac594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sending a promo if response is risk of stroke:\n",
    "#if response['stroke'] == True:\n",
    " #   print('person will have stroke %s' % ('xyz-123'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a5b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
